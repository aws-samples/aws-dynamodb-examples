Description: Provides VSCode Server, database instances, and required components without Cloud9.

Parameters:
  EnvironmentName:
    Description: An environment name that is tagged to the resources.
    Type: String
    Default: DynamoDBID
  DBLatestAmiId:
    Type:  'AWS::SSM::Parameter::Value<AWS::EC2::Image::Id>'
    Default: '/aws/service/ami-amazon-linux-latest/al2023-ami-kernel-default-arm64'
  DbMasterUsername:
    Description: The datbase master user name
    Type: String
    Default: dbuser
  ################## VSCode Server #################
  VSCodeUser:
    Type: String
    Description: Username for VS code-server
    Default: participant
  VSCodeInstanceName:
    Type: String
    Description: EC2 Instance name for VS code-server
    Default: VSCodeServer
  VSCodeInstanceVolumeSize:
    Type: Number
    Description: VS code-server EC2 instance volume size in GB
    Default: 40
  VSCodeInstanceType:
    Description: VS code-server EC2 instance type
    Type: String
    Default: t4g.large
    AllowedPattern: ^(t4g|m6g|m7g|m8g|c6g|c7g)\.[0-9a-z]+$
    ConstraintDescription: Must be a valid t, c or m series Graviton EC2 instance type
  VSCodeHomeFolder:
    Type: String
    Description: Folder to open in VS Code server
    Default: /home/participant/workshop
  PythonMajorMinor:
    Type: String
    Default: "3.13"
    Description: "Python major.minor version (e.g., 3.13) for the Code instance. Latest patch version will be installed automatically."
    AllowedPattern: "^[0-9]+\\.[0-9]+$"
    ConstraintDescription: "Must be in format X.Y (e.g., 3.13)"
  AllowedIP:
    Type: String
    Description: IP address allowed to access VSCode Server (use 0.0.0.0/0 for open access, not recommended)
    Default: "97.106.75.58/32"
    AllowedPattern: ^([0-9]{1,3}\.){3}[0-9]{1,3}(\/([0-9]|[1-2][0-9]|3[0-2]))?$
    ConstraintDescription: Must be a valid IP address in CIDR format (e.g., 1.2.3.4/32)

Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: General configuration
        Parameters:
          - EnvironmentName
      - Label:
          default: VSCode Server configuration
        Parameters:
          - VSCodeInstanceName
          - VSCodeInstanceType
          - VSCodeInstanceVolumeSize
          - VSCodeUser
          - VSCodeHomeFolder
    ParameterLabels:
      EnvironmentName:
        default: Environment name
      VSCodeInstanceName:
        default: VSCode Instance Name
      VSCodeInstanceType:
        default: VSCode Instance type
      VSCodeInstanceVolumeSize:
        default: VSCode Attached volume size
      VSCodeUser:
        default: VSCode Username
      VSCodeHomeFolder:
        default: VSCode Home Folder

Mappings:
  # AWS Managed Prefix Lists for EC2 InstanceConnect
  AWSRegions2PrefixListID:
    ap-south-1:
      PrefixList: pl-0fa83cebf909345ca
    eu-north-1:
      PrefixList: pl-0bd77a95ba8e317a6
    eu-west-3:
      PrefixList: pl-0f2a97ab210dbbae1
    eu-west-2:
      PrefixList: pl-067eefa539e593d55
    eu-west-1:
      PrefixList: pl-0839cc4c195a4e751
    ap-northeast-3:
      PrefixList: pl-086543b458dc7add9
    ap-northeast-2:
      PrefixList: pl-00ec8fd779e5b4175
    ap-northeast-1:
      PrefixList: pl-08d491d20eebc3b95
    ca-central-1:
      PrefixList: pl-0beea00ad1821f2ef
    sa-east-1:
      PrefixList: pl-029debe66aa9d13b3
    ap-southeast-1:
      PrefixList: pl-073f7512b7b9a2450
    ap-southeast-2:
      PrefixList: pl-0e1bc5673b8a57acc
    eu-central-1:
      PrefixList: pl-03384955215625250
    us-east-1:
      PrefixList: pl-0e4bcff02b13bef1e
    us-east-2:
      PrefixList: pl-03915406641cb1f53
    us-west-1:
      PrefixList: pl-0e99958a47b22d6ab
    us-west-2:
      PrefixList: pl-047d464325e7bf465

  AWSRegionsPrefixListID:
  # aws ec2 describe-managed-prefix-lists  --region <REGION> | jq -r '.PrefixLists[] | select (.PrefixListName == "com.amazonaws.global.cloudfront.origin-facing") | .PrefixListId'
    ap-northeast-1:
      PrefixList: pl-58a04531
    ap-northeast-2:
      PrefixList: pl-22a6434b
    ap-south-1:
      PrefixList: pl-9aa247f3
    ap-southeast-1:
      PrefixList: pl-31a34658
    ap-southeast-2:
      PrefixList: pl-b8a742d1
    ca-central-1:
      PrefixList: pl-38a64351
    eu-central-1:
      PrefixList: pl-a3a144ca
    eu-north-1:
      PrefixList: pl-fab65393
    eu-west-1:
      PrefixList: pl-4fa04526
    eu-west-2:
      PrefixList: pl-93a247fa
    eu-west-3:
      PrefixList: pl-75b1541c
    sa-east-1:
      PrefixList: pl-5da64334
    us-east-1:
      PrefixList: pl-3b927c52
    us-east-2:
      PrefixList: pl-b6a144df
    us-west-1:
      PrefixList: pl-4ea04527
    us-west-2:
      PrefixList: pl-82a045eb


Resources:
  #LADV Role
  DDBReplicationRole:
      Type: AWS::IAM::Role
      Properties:
        AssumeRolePolicyDocument:
          Version: '2012-10-17'
          Statement:
            - Effect: Allow
              Principal:
                Service:
                  - lambda.amazonaws.com
              Action:
                - sts:AssumeRole
        Path: /
        Policies:
          - PolicyName: root
            PolicyDocument:
              Version: '2012-10-17'
              Statement:
                - Effect: Allow
                  Action:
                    - dynamodb:DescribeStream
                    - dynamodb:GetRecords
                    - dynamodb:GetShardIterator
                    - dynamodb:ListStreams
                  Resource:
                    - '*'
                - Effect: Allow
                  Action:
                    - dynamodb:DeleteItem
                    - dynamodb:PutItem
                  Resource:
                    - '*'
                - Effect: Allow
                  Action:
                    - logs:CreateLogGroup
                    - logs:CreateLogStream
                    - logs:PutLogEvents
                  Resource:
                    - '*'

  # Glue Service Role for MySQL to DynamoDB Migration
  GlueServiceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - glue.amazonaws.com
            Action:
              - sts:AssumeRole
      ManagedPolicyArns:
        - !Sub arn:${AWS::Partition}:iam::aws:policy/service-role/AWSGlueServiceRole
        - !Sub arn:${AWS::Partition}:iam::aws:policy/AmazonDynamoDBFullAccess
      Policies:
        - PolicyName: S3MigrationBucketAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:DeleteObject
                  - s3:ListBucket
                Resource:
                  - !Sub ${MigrationS3Bucket.Arn}/*
              - Effect: Allow
                Action:
                  - s3:ListBucket
                Resource:
                  - !GetAtt MigrationS3Bucket.Arn
        - PolicyName: CloudWatchLogsAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                  - logs:DescribeLogGroups
                  - logs:DescribeLogStreams
                Resource:
                  - !Sub arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws-glue/*
                  - !Sub arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws-glue/*:log-stream:*
        - PolicyName: SecretsManagerAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - secretsmanager:GetSecretValue
                  - secretsmanager:DescribeSecret
                Resource:
                  - !Ref DbPasswordSecret
      Tags:
        - Key: Environment
          Value: !Ref EnvironmentName
        - Key: Purpose
          Value: GlueETLMigration
  ################## PERMISSIONS AND ROLES #################
  CodeInstanceRole:
    Type: AWS::IAM::Role
    Properties:
      Tags:
        - Key: Environment
          Value: !Sub ${EnvironmentName}
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - ec2.amazonaws.com
                - ssm.amazonaws.com
                - opensearchservice.amazonaws.com
                - osis-pipelines.amazonaws.com
            Action:
              - sts:AssumeRole
      ManagedPolicyArns:
        - !Sub arn:${AWS::Partition}:iam::aws:policy/AdministratorAccess
      Path: '/'

  ################ LAMBDA INSTANCE TYPE FINDER ################
  VSCodeFindTheInstanceTypeLambda:
    Type: Custom::VSCodeFindTheInstanceTypeLambda
    Properties:
      Tags:
        - Key: Environment
          Value: !Sub ${EnvironmentName}
      ServiceToken:
        Fn::GetAtt:
          - VSCodeFindTheInstanceTypeLambdaFunction
          - Arn
      Region:
        Ref: AWS::Region
      StackName:
        Ref: AWS::StackName
      InstanceType:
        Ref: VSCodeInstanceType

  VSCodeFindTheInstanceTypeLambdaFunction:
    Type: AWS::Lambda::Function
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W58
            reason: Lambda execution role has basic execution permissions
          - id: W89
            reason: Bootstrap function does not need the scaffolding of a VPC or provisioned concurrency
          - id: W92
            reason: Bootstrap function does not need provisioned concurrency   
    Properties:
      Tags:
        - Key: Environment
          Value: !Sub ${EnvironmentName}
      Handler: index.lambda_handler
      Role:
        Fn::GetAtt:
          - VSCodeLambdaExecutionRole
          - Arn
      Runtime: python3.13
      MemorySize: 1024
      Timeout: 400
      Code:
        ZipFile: |
          import json
          import boto3
          import random
          import cfnresponse
          import logging
          import traceback

          logger = logging.getLogger(__name__)

          ec2 = boto3.client('ec2')
          def lambda_handler(event, context):
              print(event.values())
              print('context: {}'.format(context))
              responseData = {}

              status = cfnresponse.SUCCESS
              if event['RequestType'] == 'Delete':
                  responseData = {'Success': 'Custom Resource removed'}
                  cfnresponse.send(event, context, status, responseData, 'CustomResourcePhysicalID')
              elif event['RequestType'] == 'Update':
                  responseData = {'Success': 'No-op'}
                  cfnresponse.send(event, context, status, responseData, 'CustomResourcePhysicalID')
              elif event['RequestType'] == 'Create':
                  try:
                      resp = ec2.describe_subnets(
                          Filters = [
                          {
                              'Name':'default-for-az',
                              'Values': ['true']
                          }])
                      inst_types = list()
                      inst_types.append(event['ResourceProperties']['InstanceType'])
                      subnet_ids = dict()
                      for subnet in resp['Subnets']:
                          subnet_ids[subnet['AvailabilityZone']] = subnet['SubnetId']
                      offerings = get_offerings(inst_types)
                      subnet_id = None
                      #hunt time
                      results = dict()
                      for instance in inst_types:
                          for az in offerings[instance]:
                              if az in subnet_ids:
                                  subnet_id = subnet_ids[az]
                                  if instance not in results:
                                      results[instance] = subnet_ids[az]
                      instance_type, subnet = random.choice(list(results.items()))
                      responseData = {'InstanceType':instance_type, 'SubnetId': subnet}
                      cfnresponse.send(event, context, status, responseData, 'CustomResourcePhysicalID')
                  except Exception as err:
                      print(err)
                      status = cfnresponse.FAILED
                      print(traceback.format_exc())
                      responseData = {'Error': traceback.format_exc(err)}
                  finally:
                      cfnresponse.send(event, context, status, responseData, 'CustomResourcePhysicalID')
                      

          def get_offerings(inst_types):
              product_types = ('Linux/UNIX (Amazon VPC)', 'Windows (Amazon VPC)')
              resp = ec2.describe_instance_type_offerings(
                  LocationType='availability-zone',
                  Filters = [
                      {
                          'Name': 'instance-type',
                          'Values': inst_types
                      }
                  ])
              offerings = dict()
              for inst in resp['InstanceTypeOfferings']:
                  if inst['InstanceType'] not in offerings:
                      offerings[inst['InstanceType']] = list()
                  offerings[inst['InstanceType']].append(inst['Location'])

              # TODO implement
              return offerings

  VSCodeLambdaExecutionRole:
    Type: AWS::IAM::Role
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W11
            reason: Describe Action doesn't support any resource condition
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: '/'
      ManagedPolicyArns:
        - !Sub arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: !Sub VSCodeLambdaPolicy-${AWS::Region}
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - cloudformation:DescribeStacks
                  - cloudformation:DescribeStackEvents
                  - cloudformation:DescribeStackResource
                  - cloudformation:DescribeStackResources
                Resource:
                  - !Sub arn:${AWS::Partition}:cloudformation:${AWS::Region}:${AWS::AccountId}:stack/*
              - Effect: Allow
                Action:
                  - ec2:AssociateIamInstanceProfile
                  - ec2:ModifyInstanceAttribute
                  - ec2:ReplaceIamInstanceProfileAssociation
                  - ec2:RebootInstances
                Resource:
                  - !Sub arn:${AWS::Partition}:ec2:${AWS::Region}:${AWS::AccountId}:instance/*
              - Effect: Allow
                Action:
                  - ec2:DescribeInstances
                  - ec2:DescribeVolumesModifications
                  - ec2:DescribeVolumes
                  - ec2:DescribeIamInstanceProfileAssociations
                  - ec2:ModifyVolume
                  - ssm:DescribeInstanceInformation
                  - ssm:SendCommand
                  - ssm:GetCommandInvocation
                  - ec2:DescribeSubnets
                  - ec2:DescribeInstanceTypeOfferings
                Resource: '*'
              - Effect: Allow
                Action:
                  - iam:ListInstanceProfiles
                Resource:
                  - !Sub arn:${AWS::Partition}:iam::${AWS::AccountId}:instance-profile/*
              - Effect: Allow
                Action:
                  - iam:PassRole
                Resource:
                  Fn::GetAtt:
                    - CodeInstanceRole
                    - Arn

  ############ RELATIONAL MIGRATION  STAGING BUCKET #########
  MigrationS3Bucket:
    Type: AWS::S3::Bucket

################ VSCode Server ################
  VSCodeSecret:
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W77
            reason: The default KMS Key used by Secrets Manager is appropriate for this password which will be used to log into VSCodeServer, which has very limited permissions. In addition this secret will not be required to be shared across accounts
    Type: AWS::SecretsManager::Secret
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Properties:
      Name: !Sub ${AWS::StackName}-VSCodeServer
      Description: VS code-server user details
      GenerateSecretString:
        PasswordLength: 16
        SecretStringTemplate: !Sub '{"username":"${VSCodeUser}"}'
        GenerateStringKey: "password"
        ExcludePunctuation: true

  DbPasswordSecret:
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W77
            reason: The default KMS Key used by Secrets Manager is appropriate for this password which will be used for database access
    Type: AWS::SecretsManager::Secret
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Properties:
      Name: !Sub ${AWS::StackName}-DatabasePassword
      Description: Auto-generated MySQL database password
      GenerateSecretString:
        PasswordLength: 24
        ExcludeCharacters: '"@/\`{}$!&*()[]|;:<>?''%#^+=~'
        ExcludePunctuation: false
        IncludeSpace: false

  SecretPlaintextLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: !Sub lambda.${AWS::URLSuffix}
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - !Sub arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: AwsSecretsManager
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - secretsmanager:GetSecretValue
                Resource: 
                  - !Ref VSCodeSecret
                  - !Ref DbPasswordSecret

  DbPasswordPlaintextLambda:
    Type: AWS::Lambda::Function
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W58
            reason: Warning incorrectly reported. The role associated with the Lambda function has the AWSLambdaBasicExecutionRole managed policy attached, which includes permission to write CloudWatch Logs. See https://docs.aws.amazon.com/aws-managed-policy/latest/reference/AWSLambdaBasicExecutionRole.html
          - id: W89
            reason: CloudFormation custom function does not need the scaffolding of a VPC, to do so would add unnecessary complexity
          - id: W92
            reason: CloudFormation custom function does not need reserved concurrent executions, to do so would add unnecessary complexity
    Properties:
      Description: Return the value of the database password secret
      Handler: index.lambda_handler
      Runtime: python3.13
      MemorySize: 128
      Timeout: 10
      Architectures:
        - arm64
      Role: !GetAtt SecretPlaintextLambdaRole.Arn
      Code:
        ZipFile: |
          import boto3
          import json
          import cfnresponse
          import logging

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def lambda_handler(event, context):
              logger.debug(f'event: {event}')
              logger.debug(f'context: {context}')
              try:
                  if event['RequestType'] == 'Delete':
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData={}, reason='No action to take')
                  else:
                      resource_properties = event['ResourceProperties']
                      secret_name = resource_properties['SecretArn']
                      secrets_mgr = boto3.client('secretsmanager')

                      logger.info('Getting secret from %s', secret_name)

                      secret = secrets_mgr.get_secret_value(SecretId = secret_name)
                      logger.debug(f'secret: {secret}')
                      secret_value = secret['SecretString']

                      responseData = {'password': secret_value}
                      logger.debug(f'responseData: {responseData}')
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData=responseData, reason='OK', noEcho=True)
              except Exception as e:
                  logger.error(e)
                  cfnresponse.send(event, context, cfnresponse.FAILED, responseData={}, reason=str(e))

  DbPasswordPlaintext:
    Type: Custom::DbPasswordPlaintextLambda
    Properties:
      ServiceToken: !GetAtt DbPasswordPlaintextLambda.Arn
      ServiceTimeout: 15
      SecretArn: !Ref DbPasswordSecret

  SecretPlaintextLambda:
    Type: AWS::Lambda::Function
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W58
            reason: Warning incorrectly reported. The role associated with the Lambda function has the AWSLambdaBasicExecutionRole managed policy attached, which includes permission to write CloudWatch Logs. See https://docs.aws.amazon.com/aws-managed-policy/latest/reference/AWSLambdaBasicExecutionRole.html
          - id: W89
            reason: CloudFormation custom function does not need the scaffolding of a VPC, to do so would add unnecessary complexity
          - id: W92
            reason: CloudFormation custom function does not need reserved concurrent executions, to do so would add unnecessary complexity
    Properties:
      Description: Return the value of the secret
      Handler: index.lambda_handler
      Runtime: python3.13
      MemorySize: 128
      Timeout: 10
      Architectures:
        - arm64
      Role: !GetAtt SecretPlaintextLambdaRole.Arn
      Code:
        ZipFile: |
          import boto3
          import json
          import cfnresponse
          import logging

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def is_valid_json(json_string):
              logger.debug(f'Calling is_valid_jason:{json_string}')
              try:
                  json.loads(json_string)
                  logger.info('Secret is in json format')
                  return True
              except json.JSONDecodeError:
                  logger.info('Secret is in string format')
                  return False

          def lambda_handler(event, context):
              logger.debug(f'event: {event}')
              logger.debug(f'context: {context}')
              try:
                  if event['RequestType'] == 'Delete':
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData={}, reason='No action to take')
                  else:
                      resource_properties = event['ResourceProperties']
                      secret_name = resource_properties['SecretArn']
                      secrets_mgr = boto3.client('secretsmanager')

                      logger.info('Getting secret from %s', secret_name)

                      secret = secrets_mgr.get_secret_value(SecretId = secret_name)
                      logger.debug(f'secret: {secret}')
                      secret_value = secret['SecretString']

                      responseData = {}
                      if is_valid_json(secret_value):
                          responseData = secret_value
                      else:
                          responseData = {'secret': secret_value}
                      logger.debug(f'responseData: {responseData}')
                      logger.debug(f'type(responseData): {type(responseData)}')
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData=json.loads(responseData), reason='OK', noEcho=True)
              except Exception as e:
                  logger.error(e)
                  cfnresponse.send(event, context, cfnresponse.FAILED, responseData={}, reason=str(e))

  SecretPlaintext:
    Type: Custom::SecretPlaintextLambda
    Properties:
      ServiceToken: !GetAtt SecretPlaintextLambda.Arn
      ServiceTimeout: 15
      SecretArn: !Ref VSCodeSecret

  VSCodeSSMDoc:
    Type: AWS::SSM::Document
    Properties:
      DocumentType: Command
      Content:
        schemaVersion: "2.2"
        description: Bootstrap VS code-server instance
        parameters:
          LinuxFlavor:
            type: String
            default: "al2023"
          VSCodePassword:
            type: String
            default: !Ref AWS::StackId
          PythonMajorMinor:
            type: String
            default: "3.13"
        # all mainSteps scripts are in in /var/lib/amazon/ssm/<instanceid>/document/orchestration/<uuid>/<StepName>/_script.sh
        mainSteps:
          # This step was needed to avoid "Can't create transaction lock" error likely due to competing install
          - name: RemoveTransactionLock
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 300
              runCommand:
                - "#!/bin/bash"
                - sudo rm -f /var/lib/rpm/.rpm.lock
          - name: InstallCloudWatchAgent
            action: aws:configurePackage
            inputs:
              name: AmazonCloudWatchAgent
              action: Install
          - name: ConfigureCloudWatchAgent
            action: aws:runDocument
            inputs:
              documentType: SSMDocument
              documentPath: AmazonCloudWatch-ManageAgent
              documentParameters:
                action: configure
                mode: ec2
                optionalConfigurationSource: default
                optionalRestart: "yes"
          - name: InstallBasePackagesDnf
            action: aws:runShellScript
            precondition:
              StringEquals:
                - "{{ LinuxFlavor }}"
                - al2023
            inputs:
              timeoutSeconds: 300
              runCommand:
                - "#!/bin/bash"
                - dnf install -y --allowerasing curl gnupg whois argon2 unzip nginx openssl
          - name: AddUserDnf
            action: aws:runShellScript
            precondition:
              StringEquals:
                - "{{ LinuxFlavor }}"
                - al2023
            inputs:
              timeoutSeconds: 300
              runCommand:
                - "#!/bin/bash"
                - !Sub |
                  echo 'Adding user: ${VSCodeUser}'
                  adduser -c '' ${VSCodeUser}
                  passwd -l ${VSCodeUser}
                  echo "${VSCodeUser}:{{ VSCodePassword }}" | chpasswd
                  usermod -aG wheel ${VSCodeUser}
                  echo "participant ALL=(ALL) NOPASSWD: ALL" | sudo tee /etc/sudoers.d/participant
                  sudo chmod 440 /etc/sudoers.d/participant
                - echo "User added. Checking configuration"
                - !Sub getent passwd ${VSCodeUser}
          - name: UpdateProfile
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 300
              runCommand:
                - "#!/bin/bash"
                - echo LANG=en_US.utf-8 >> /etc/environment
                - echo LC_ALL=en_US.UTF-8 >> /etc/environment
                - !Sub echo 'PATH=$PATH:/home/${VSCodeUser}/.local/bin' >> /home/${VSCodeUser}/.bashrc
                - !Sub echo 'export PATH' >> /home/${VSCodeUser}/.bashrc
                - !Sub echo 'export AWS_REGION=${AWS::Region}' >> /home/${VSCodeUser}/.bashrc
                - !Sub echo 'export AWS_ACCOUNTID=${AWS::AccountId}' >> /home/${VSCodeUser}/.bashrc
                - !Sub echo 'export NEXT_TELEMETRY_DISABLED=1' >> /home/${VSCodeUser}/.bashrc
                - !Sub echo "export PS1='\[\033[01;32m\]\u:\[\033[01;34m\]\w\[\033[00m\]\$ '" >> /home/${VSCodeUser}/.bashrc
                - !Sub chown -R ${VSCodeUser}:${VSCodeUser} /home/${VSCodeUser}
          - name: InstallAWSCLI
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 300
              runCommand:
                - "#!/bin/bash"
                - mkdir -p /tmp
                - curl -fsSL https://awscli.amazonaws.com/awscli-exe-linux-$(uname -m).zip -o /tmp/aws-cli.zip
                - !Sub chown -R ${VSCodeUser}:${VSCodeUser} /tmp/aws-cli.zip
                - unzip -q -d /tmp /tmp/aws-cli.zip
                - sudo /tmp/aws/install
                - rm -rf /tmp/aws
                - echo "AWS CLI installed. Checking configuration"
                - aws --version
          - name: InstallGitDnf
            action: aws:runShellScript
            precondition:
              StringEquals:
                - "{{ LinuxFlavor }}"
                - al2023
            inputs:
              timeoutSeconds: 300
              runCommand:
                - "#!/bin/bash"
                - dnf install -y git
                - !Sub sudo -u ${VSCodeUser} git config --global user.email "participant@example.com"
                - !Sub sudo -u ${VSCodeUser} git config --global user.name "Workshop Participant"
                - !Sub sudo -u ${VSCodeUser} git config --global init.defaultBranch "main"
                - echo "Git installed. Checking configuration"
                - git --version
          - name: ConfigureCodeServer
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 600
              runCommand:
                - "#!/bin/bash"
                - !Sub export HOME=/home/${VSCodeUser}
                - curl -fsSL https://code-server.dev/install.sh | bash -s -- 2>&1
                - !Sub systemctl enable --now code-server@${VSCodeUser} 2>&1
                - !Sub |
                  tee /etc/nginx/conf.d/code-server.conf <<EOF
                  server {
                      listen 80;
                      listen [::]:80;
                      server_name *.cloudfront.net;
                      
                      # Root directory for static files
                      root /var/www/html;
                      
                      # Enable gzip compression for better performance
                      gzip on;
                      gzip_vary on;
                      gzip_min_length 1024;
                      gzip_proxied any;
                      gzip_types
                          text/plain
                          text/css
                          text/xml
                          text/javascript
                          application/javascript
                          application/xml+rss
                          application/json;

                      # Security headers
                      add_header X-Frame-Options "SAMEORIGIN" always;
                      add_header X-Content-Type-Options "nosniff" always;
                      add_header X-XSS-Protection "1; mode=block" always;
                      add_header Referrer-Policy "strict-origin-when-cross-origin" always;
                      
                      # Health check endpoint for CloudFormation
                      location /healthz {
                        access_log off;
                        return 200 '{"status":"alive"}';
                        add_header Content-Type application/json;
                      }
                      
                      # VS Code Server (default route)
                      location / {
                        proxy_pass http://localhost:8080/;
                        proxy_set_header Host \$host;
                        proxy_set_header Upgrade \$http_upgrade;
                        proxy_set_header Connection upgrade;
                        proxy_set_header Accept-Encoding gzip;
                        proxy_set_header X-Real-IP \$remote_addr;
                        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
                        proxy_set_header X-Forwarded-Proto \$scheme;
                      }
                      
                      # ========================================
                      # DEVELOPMENT MODE - React App at /store (Development Server)
                      # ========================================
                      
                      # React Frontend on port 3000 (development mode for live updates)
                      location /store/ {
                        proxy_pass http://localhost:3000/;
                        proxy_set_header Host \$host;
                        proxy_set_header X-Real-IP \$remote_addr;
                        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
                        proxy_set_header X-Forwarded-Proto \$scheme;
                        proxy_set_header Upgrade \$http_upgrade;
                        proxy_set_header Connection "upgrade";
                        
                        # Handle timeouts
                        proxy_connect_timeout 60s;
                        proxy_send_timeout 60s;
                        proxy_read_timeout 60s;
                        
                        # Buffer settings for live updates
                        proxy_buffering off;
                        proxy_request_buffering off;
                        
                        # Disable caching for development
                        add_header Cache-Control "no-cache, no-store, must-revalidate";
                        add_header Pragma "no-cache";
                        add_header Expires "0";
                      }
                      
                      # Handle /store without trailing slash
                      location = /store {
                        return 301 /store/;
                      }
                      
                      # Handle React static assets - proxy directly to development server
                      location /static/ {
                        proxy_pass http://localhost:3000;
                        proxy_set_header Host \$host;
                        proxy_set_header X-Real-IP \$remote_addr;
                        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
                        proxy_set_header X-Forwarded-Proto \$scheme;
                        
                        # Cache static assets
                        expires 1y;
                        add_header Cache-Control "public, immutable";
                      }
                      
                      # Express Backend API on port 8100
                      location /api/ {
                        proxy_pass http://localhost:8100/api/;
                        proxy_set_header Host \$host;
                        proxy_set_header X-Real-IP \$remote_addr;
                        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
                        proxy_set_header X-Forwarded-Proto \$scheme;
                        
                        # CORS headers for API requests
                        add_header 'Access-Control-Allow-Origin' '*' always;
                        add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, DELETE, OPTIONS' always;
                        add_header 'Access-Control-Allow-Headers' 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization' always;
                        
                        # Handle preflight requests
                        if (\$request_method = OPTIONS) {
                            add_header 'Access-Control-Allow-Origin' '*';
                            add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS, PUT, DELETE';
                            add_header 'Access-Control-Allow-Headers' 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization';
                            add_header 'Access-Control-Max-Age' 1728000;
                            add_header 'Content-Type' 'text/plain; charset=utf-8';
                            add_header 'Content-Length' 0;
                            return 204;
                        }
                      }
                      
                      # Legacy /app route (keeping for backward compatibility)
                      location /app {
                        proxy_pass http://localhost:8081/app;
                        proxy_set_header Host \$host;
                        proxy_set_header Upgrade \$http_upgrade;
                        proxy_set_header Connection upgrade;
                        proxy_set_header Accept-Encoding gzip;
                      }
                  }
                  EOF
                - !Sub mkdir -p /home/${VSCodeUser}/.config/code-server
                - !Sub |
                  tee /home/${VSCodeUser}/.config/code-server/config.yaml <<EOF
                  cert: false
                  auth: password
                  hashed-password: "$(echo -n {{ VSCodePassword }} | argon2 $(openssl rand -base64 12) -e)"
                  EOF
                - !Sub mkdir -p /home/${VSCodeUser}/.local/share/code-server/User/
                - !Sub touch /home/${VSCodeUser}/.hushlogin
                - !Sub mkdir -p ${VSCodeHomeFolder} && chown -R ${VSCodeUser}:${VSCodeUser} ${VSCodeHomeFolder}
                - !Sub |
                  tee /home/${VSCodeUser}/.local/share/code-server/User/settings.json <<EOF
                  {
                    "extensions.autoUpdate": false,
                    "extensions.autoCheckUpdates": false,
                    "telemetry.telemetryLevel": "off",
                    "security.workspace.trust.startupPrompt": "never",
                    "security.workspace.trust.enabled": false,
                    "security.workspace.trust.banner": "never",
                    "security.workspace.trust.emptyWindow": false,
                    "auto-run-command.rules": [
                      {
                        "command": "workbench.action.terminal.new"
                      }
                    ]
                  }
                  EOF
                - !Sub chown -R ${VSCodeUser}:${VSCodeUser} /home/${VSCodeUser}
                - echo "Starting and configuring services..."
                - echo "Stopping any existing nginx processes..."
                - pkill nginx || true
                - systemctl stop nginx || true
                - echo "Starting nginx service..."
                - systemctl enable nginx
                - systemctl start nginx
                - echo "Starting code-server service..."
                - !Sub systemctl restart code-server@${VSCodeUser}
                - echo "Installing VSCode extensions..."
                - !Sub sudo -u ${VSCodeUser} --login code-server --install-extension AmazonWebServices.aws-toolkit-vscode --force
                - !Sub sudo -u ${VSCodeUser} --login code-server --install-extension ms-vscode.live-server --force
                - !Sub sudo -u ${VSCodeUser} --login code-server --install-extension synedra.auto-run-command --force
                - !Sub sudo -u ${VSCodeUser} --login code-server --install-extension saoudrizwan.claude-dev --force
                - !Sub chown -R ${VSCodeUser}:${VSCodeUser} /home/${VSCodeUser}
                - echo "Verifying services..."
                - nginx -t 2>&1
                - systemctl status nginx --no-pager
                - echo "CodeServer installed. Checking configuration"
                - code-server -v
                - !Sub systemctl status code-server@${VSCodeUser} --no-pager
          - name: InstallLADVDeps
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 1200
              runCommand:
                - "#!/bin/bash"
                # Workshop files are no longer downloaded
                - !Sub "mkdir -p ${VSCodeHomeFolder}/{LHOL,LBED,LADV,LSQL,LMR,LEDA,LGME,LGAM,LDMS,LDC,LCDC}"
                - echo "Workshop folder setup (no download required)"
                - !Sub echo "${DDBReplicationRole.Arn}" > ${VSCodeHomeFolder}/ddb-replication-role-arn.txt
                - !Sub chown -R ${VSCodeUser}:${VSCodeUser} ${VSCodeHomeFolder}
                - echo "Installing pyenv dependencies..."
                - dnf install -y make gcc zlib-devel bzip2 bzip2-devel readline-devel sqlite sqlite-devel openssl-devel tk-devel libffi-devel xz-devel > /dev/null
                - echo "Installing pyenv for VSCode user..."
                - !Sub sudo -u ${VSCodeUser} bash -c 'curl https://pyenv.run | bash'
                - echo "Configuring pyenv in shell profiles..."
                - !Sub echo 'export PYENV_ROOT="$HOME/.pyenv"' >> /home/${VSCodeUser}/.bashrc
                - !Sub echo 'command -v pyenv >/dev/null || export PATH="$PYENV_ROOT/bin:$PATH"' >> /home/${VSCodeUser}/.bashrc
                - !Sub echo 'eval "$(pyenv init -)"' >> /home/${VSCodeUser}/.bashrc
                - echo "Installing Python {{ PythonMajorMinor }}:latest using pyenv..."
                - !Sub sudo -u ${VSCodeUser} bash -c 'source ~/.bashrc && pyenv install {{ PythonMajorMinor }}:latest'
                - echo "Getting installed Python version and setting global..."
                - !Sub sudo -u ${VSCodeUser} bash -c 'source ~/.bashrc && PYTHON_VERSION=$(pyenv versions --bare | grep "^{{ PythonMajorMinor }}" | tail -1) && echo "Setting global Python version to $PYTHON_VERSION" && pyenv global $PYTHON_VERSION'
                - echo "Installing required Python packages..."
                - !Sub sudo -u ${VSCodeUser} bash -c 'source ~/.bashrc && pip install boto3 opensearch-py'
                - echo "Creating symlink for backward compatibility..."
                - !Sub sudo -u ${VSCodeUser} bash -c 'source ~/.bashrc && sudo ln -sf $(pyenv which python) /usr/local/bin/python'
                - !Sub chown -R ${VSCodeUser}:${VSCodeUser} /home/${VSCodeUser}/.pyenv
                - echo "Python installation completed. Version:"
                - !Sub sudo -u ${VSCodeUser} bash -c 'source ~/.bashrc && python --version'
          - name: InstallNode
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 600
              runCommand:
                - "#!/bin/bash"
                - echo "Installing Node.js using nvm..."
                - !Sub |
                  # Install nvm as participant user
                  sudo -u ${VSCodeUser} bash -c 'curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash'
                - !Sub |
                  # Install Node.js 18 as participant user and set as default
                  sudo -u ${VSCodeUser} bash -c 'export NVM_DIR="$HOME/.nvm" && [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh" && nvm install 18 && nvm use 18 && nvm alias default 18'
                - echo "Adding nvm configuration to shell profiles..."
                - !Sub |
                  # Add to .bashrc for interactive bash shells
                  cat >> /home/${VSCodeUser}/.bashrc <<EOF
                  # NVM configuration
                  export NVM_DIR="\$HOME/.nvm"
                  [ -s "\$NVM_DIR/nvm.sh" ] && \. "\$NVM_DIR/nvm.sh"
                  [ -s "\$NVM_DIR/bash_completion" ] && \. "\$NVM_DIR/bash_completion"
                  EOF
                - !Sub |
                  # Add to .zshrc for interactive zsh shells
                  cat >> /home/${VSCodeUser}/.zshrc <<EOF
                  # NVM configuration
                  export NVM_DIR="\$HOME/.nvm"
                  [ -s "\$NVM_DIR/nvm.sh" ] && \. "\$NVM_DIR/nvm.sh"
                  [ -s "\$NVM_DIR/bash_completion" ] && \. "\$NVM_DIR/bash_completion"
                  EOF
                - !Sub |
                  # Add to .profile for login shells and non-interactive shells
                  cat >> /home/${VSCodeUser}/.profile <<EOF
                  # NVM configuration
                  export NVM_DIR="\$HOME/.nvm"
                  [ -s "\$NVM_DIR/nvm.sh" ] && \. "\$NVM_DIR/nvm.sh"
                  [ -s "\$NVM_DIR/bash_completion" ] && \. "\$NVM_DIR/bash_completion"
                  EOF
                - !Sub |
                  # Ensure .local/bin directory exists first
                  sudo -u ${VSCodeUser} mkdir -p /home/${VSCodeUser}/.local/bin
                - !Sub |
                  # Create symlinks for global access
                  sudo -u ${VSCodeUser} bash -c 'export NVM_DIR="$HOME/.nvm" && [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh" && ln -sf $(which node) /home/${VSCodeUser}/.local/bin/node'
                  sudo -u ${VSCodeUser} bash -c 'export NVM_DIR="$HOME/.nvm" && [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh" && ln -sf $(which npm) /home/${VSCodeUser}/.local/bin/npm'
                  sudo -u ${VSCodeUser} bash -c 'export NVM_DIR="$HOME/.nvm" && [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh" && ln -sf $(which npx) /home/${VSCodeUser}/.local/bin/npx'
                - !Sub |
                  # Create global symlinks in /usr/local/bin for system-wide access
                  sudo bash -c 'export NVM_DIR="/home/${VSCodeUser}/.nvm" && [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh" && ln -sf $(which node) /usr/local/bin/node'
                  sudo bash -c 'export NVM_DIR="/home/${VSCodeUser}/.nvm" && [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh" && ln -sf $(which npm) /usr/local/bin/npm'
                  sudo bash -c 'export NVM_DIR="/home/${VSCodeUser}/.nvm" && [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh" && ln -sf $(which npx) /usr/local/bin/npx'
                - !Sub chown -R ${VSCodeUser}:${VSCodeUser} /home/${VSCodeUser}
                - echo "Node.js installation completed. Checking version:"
                - !Sub sudo -u ${VSCodeUser} bash -c 'source ~/.bashrc && node --version'
                - !Sub sudo -u ${VSCodeUser} bash -c 'source ~/.bashrc && npm --version'
                - echo "Verifying global access:"
                - !Sub sudo -u ${VSCodeUser} bash -c '/home/${VSCodeUser}/.local/bin/node --version'
                - !Sub sudo -u ${VSCodeUser} bash -c '/home/${VSCodeUser}/.local/bin/npm --version'
          - name: SetupMySQL
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 300
              runCommand:
                - "#!/bin/bash"
                - echo "Starting MySQL setup..."
                - sudo rpm --import https://repo.mysql.com/RPM-GPG-KEY-mysql-2023
                - sudo dnf install https://dev.mysql.com/get/mysql80-community-release-el9-1.noarch.rpm -y
                - echo "Installing MySQL client and server..."
                - sudo dnf install mysql-community-client mysql-community-server -y
                - echo "Starting and enabling MySQL service..."
                - sudo systemctl enable mysqld
                - sudo systemctl start mysqld
                - echo "Waiting for MySQL to be ready..."
                - for i in {1..30}; do
                - "  if systemctl is-active --quiet mysqld; then"
                - "    echo 'MySQL service is active'"
                - "    break"
                - "  fi"
                - "  echo 'Waiting for MySQL service... ($i/30)'"
                - "  sleep 2"
                - done
                - echo "Getting temporary root password..."
                - TEMP_PASSWORD=$(sudo grep 'temporary password' /var/log/mysqld.log | awk '{print $NF}' | tail -1)
                - if [ -z "$TEMP_PASSWORD" ]; then
                - "  echo 'ERROR: Could not find temporary password in MySQL log'"
                - "  exit 1"
                - fi
                - echo "Found temporary password, configuring MySQL..."
                - !Sub |
                  mysql -u root -p"$TEMP_PASSWORD" --connect-expired-password -e "SET GLOBAL validate_password.policy=LOW;" || {
                    echo "Failed to set password policy, trying alternative method..."
                    mysql -u root -p"$TEMP_PASSWORD" --connect-expired-password -e "SET GLOBAL validate_password_policy=LOW;" || {
                      echo "Warning: Could not set password validation policy"
                    }
                  }
                - !Sub |
                  mysql -u root -p"$TEMP_PASSWORD" --connect-expired-password -e "ALTER USER 'root'@'localhost' IDENTIFIED BY '${DbPasswordPlaintext.password}';" || {
                    echo "ERROR: Failed to change root password"
                    exit 1
                  }
                - !Sub |
                  mysql -u root -p"${DbPasswordPlaintext.password}" -e "CREATE USER IF NOT EXISTS '${DbMasterUsername}'@'%' IDENTIFIED BY '${DbPasswordPlaintext.password}';" || {
                    echo "ERROR: Failed to create user"
                    exit 1
                  }
                - !Sub |
                  mysql -u root -p"${DbPasswordPlaintext.password}" -e "GRANT ALL PRIVILEGES ON *.* TO '${DbMasterUsername}'@'%';" || {
                    echo "ERROR: Failed to grant privileges"
                    exit 1
                  }
                - !Sub mysql -u root -p"${DbPasswordPlaintext.password}" -e "FLUSH PRIVILEGES;"
                - !Sub mysql -u root -p"${DbPasswordPlaintext.password}" -e "CREATE DATABASE IF NOT EXISTS app_db;"
                - !Sub mysql -u root -p"${DbPasswordPlaintext.password}" -e "CREATE DATABASE IF NOT EXISTS online_shopping_store;"
                - echo "Configuring MySQL for remote connections and performance logging..."
                - !Sub |
                  mysql -u root -p"${DbPasswordPlaintext.password}" -e "
                  UPDATE mysql.user SET host='%' WHERE user='root';
                  UPDATE mysql.user SET host='%' WHERE user='${DbMasterUsername}';
                  FLUSH PRIVILEGES;
                  "
                - echo "Configuring MySQL settings for remote access and performance logging..."
                - !Sub |
                  # Backup original config file
                  cp /etc/my.cnf /etc/my.cnf.backup
                  
                  # Create MySQL configuration directory if it doesn't exist
                  mkdir -p /etc/mysql/mysql.conf.d
                  
                  # Create custom configuration file for remote access
                  cat > /etc/mysql/mysql.conf.d/remote-access.cnf <<EOF
                  [mysqld]
                  # Remote access configuration
                  bind-address = 0.0.0.0
                  
                  # Performance logging configuration
                  slow_query_log = 1
                  slow_query_log_file = /var/log/mysql/mysql-slow.log
                  long_query_time = 2
                  log_queries_not_using_indexes = 1
                  
                  # General query log (optional - can generate large logs)
                  general_log = 1
                  general_log_file = /var/log/mysql/mysql-general.log
                  
                  # Performance schema for detailed monitoring
                  performance_schema = ON
                  
                  # Additional security and connection settings
                  max_connections = 200
                  max_user_connections = 100
                  EOF
                  
                  # Also add to main config file as fallback
                  cat >> /etc/my.cnf <<EOF
                  
                  [mysqld]
                  # Remote access configuration
                  bind-address = 0.0.0.0
                  EOF
                - echo "Creating MySQL log directory and setting permissions..."
                - sudo mkdir -p /var/log/mysql
                - sudo chown mysql:mysql /var/log/mysql
                - sudo chmod 755 /var/log/mysql
                - echo "Restarting MySQL to apply configuration changes..."
                - sudo systemctl restart mysqld
                - echo "Waiting for MySQL to restart..."
                - for i in {1..15}; do
                - "  if systemctl is-active --quiet mysqld; then"
                - "    echo 'MySQL service restarted successfully'"
                - "    break"
                - "  fi"
                - "  echo 'Waiting for MySQL restart... ($i/15)'"
                - "  sleep 2"
                - done
                - echo "Adding MySQL configuration to .bashrc..."
                - !Sub |
                  cat >> /home/${VSCodeUser}/.bashrc <<EOF
                  # MySQL configuration
                  PATH=$PATH:/usr/local/bin
                  export PATH
                  export AWS_ACCOUNT_ID="${AWS::AccountId}"
                  export AWS_REGION="${AWS::Region}"
                  export AWS_DEFAULT_REGION="${AWS::Region}"
                  export MYSQL_PASSWORD="${DbPasswordPlaintext.password}"
                  export MYSQL_USERNAME="${DbMasterUsername}"
                  EOF
                - !Sub chown -R ${VSCodeUser}:${VSCodeUser} /home/${VSCodeUser}
                - echo "MySQL setup completed successfully."
                - echo "Verifying MySQL installation..."
                - sudo systemctl status mysqld
                - !Sub mysql -u ${DbMasterUsername} -p"${DbPasswordPlaintext.password}" -e "SHOW DATABASES;"
          - name: InstallModernizer
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 1200
              runCommand:
                - "#!/bin/bash"
                - "set -euo pipefail"
                - echo "Setting up Modernizer environment for participant user..."
                - !Sub |
                  # Create AWS config directory as participant user
                  sudo -u ${VSCodeUser} mkdir -p /home/${VSCodeUser}/.aws
                  sudo -u ${VSCodeUser} chmod 755 /home/${VSCodeUser}/.aws
                - !Sub |
                  # Create AWS config file as participant user
                  sudo -u ${VSCodeUser} touch /home/${VSCodeUser}/.aws/config
                  sudo -u ${VSCodeUser} chmod 644 /home/${VSCodeUser}/.aws/config
                - !Sub |
                  # Write AWS config as participant user
                  sudo -u ${VSCodeUser} bash -c 'cat > /home/${VSCodeUser}/.aws/config <<EOF
                  [default]
                  region = us-west-2
                  EOF'
                - !Sub |
                  # Install uv as participant user
                  sudo -u ${VSCodeUser} bash -c 'curl -LsSf https://astral.sh/uv/install.sh | sh'
                - !Sub |
                  # Create amazonq directory as participant user
                  sudo -u ${VSCodeUser} mkdir -p /home/${VSCodeUser}/.aws/amazonq
                  sudo -u ${VSCodeUser} chmod 755 /home/${VSCodeUser}/.aws/amazonq
                - !Sub |
                  # Create MCP config file as participant user
                  sudo -u ${VSCodeUser} bash -c 'cat > /home/${VSCodeUser}/.aws/amazonq/mcp.json <<'\''EOF'\''
                  {
                    "mcpServers": {
                      "awslabs.dynamodb-mcp-server": {
                        "command": "uvx",
                        "args": ["awslabs.dynamodb-mcp-server@latest"],
                        "env": {
                          "DDB-MCP-READONLY": "true",
                          "AWS_PROFILE": "default",
                          "AWS_REGION": "us-west-2",
                          "FASTMCP_LOG_LEVEL": "ERROR"
                        },
                        "disabled": false,
                        "autoApprove": []
                      },
                      "mysql": {
                        "type": "stdio",
                        "command": "uvx",
                        "args": [
                          "--from",
                          "mysql-mcp-server",
                          "mysql_mcp_server"
                        ],
                        "env": {
                          "MYSQL_HOST": "127.0.0.1",
                          "MYSQL_PORT": "3306",
                          "MYSQL_USER": "${DbMasterUsername}",
                          "MYSQL_PASSWORD": "${DbPasswordPlaintext.password}",
                          "MYSQL_DATABASE": "online_shopping_store"
                        }
                      }
                    }
                  }
                  EOF'
                - echo "Modernizer setup completed successfully."
          - name: InstallDocker
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 1200
              runCommand:
                - "#!/bin/bash"
                - "set -euo pipefail"
                - echo "Installing Docker..."
                - yum install docker -y
                - systemctl start docker
                - systemctl enable docker
                - !Sub "usermod -aG docker ${VSCodeUser}"
                - echo "Installing Docker Compose..."
                - "curl -L https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose"
                - "chmod +x /usr/local/bin/docker-compose"
                - echo "Verifying Docker installation..."
                - "docker --version"
                - "docker-compose --version"
                - echo "Docker installation completed successfully."
          - name: CloneWorkshop
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 1200
              runCommand:
                - "#!/bin/bash"
                - "set -euo pipefail"
                - echo "Cloning workshop repository..."
                - !Sub |
                  # Clone repository as participant user
                  sudo -u ${VSCodeUser} bash -c 'cd /home/${VSCodeUser} && git clone https://github.com/aws-samples/aws-dynamodb-examples.git'
                - !Sub |
                  # Copy files as participant user
                  sudo -u ${VSCodeUser} bash -c 'cd /home/${VSCodeUser}/aws-dynamodb-examples/workshops/modernizer && cp -R * ${VSCodeHomeFolder}/LGAM/'
                - echo "Workshop repository cloned successfully."
          - name: ConfigureBackendEnv
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 300
              runCommand:
                - "#!/bin/bash"
                - "set -euo pipefail"
                - echo "Configuring backend .env file with database credentials..."
                - !Sub |
                  # Update .env file with correct database credentials as participant user
                  if [ -f "${VSCodeHomeFolder}/LGAM/backend/.env" ]; then
                    sudo -u ${VSCodeUser} sed -i "s/^DB_USER=.*/DB_USER=\"${DbMasterUsername}\"/" ${VSCodeHomeFolder}/LGAM/backend/.env
                    sudo -u ${VSCodeUser} sed -i "s/^DB_PASSWORD=.*/DB_PASSWORD=\"${DbPasswordPlaintext.password}\"/" ${VSCodeHomeFolder}/LGAM/backend/.env
                    sudo -u ${VSCodeUser} sed -i "s/^JWT_SECRET=.*/JWT_SECRET=63de917288d776db7e6761b183bc1fd8ffc5905565d30c635294c25cc574adc496062bc59cc4370479ecbf1e826fff3c12abe4a6ecbc5203a4d58ca24a86e6fa/" ${VSCodeHomeFolder}/LGAM/backend/.env
                    echo "Updated .env file with database credentials and JWT secret"
                  else
                    echo "Warning: .env file not found, creating new one with full configuration"
                    sudo -u ${VSCodeUser} bash -c 'cat > ${VSCodeHomeFolder}/LGAM/backend/.env <<EOF
                    # Database Configuration
                    DB_HOST=localhost
                    DB_PORT=3306
                    DB_USER="${DbMasterUsername}"
                    DB_PASSWORD="${DbPasswordPlaintext.password}"
                    DB_NAME=online_shopping_store
                    DB_CONNECTION_LIMIT=10
                    DB_ACQUIRE_TIMEOUT=60000
                    DB_TIMEOUT=60000

                    # Server Configuration
                    PORT=8100

                    # JWT Configuration (IMPORTANT: Change this in production!)
                    JWT_SECRET=63de917288d776db7e6761b183bc1fd8ffc5905565d30c635294c25cc574adc496062bc59cc4370479ecbf1e826fff3c12abe4a6ecbc5203a4d58ca24a86e6fa
                    JWT_EXPIRES_IN=24h

                    # Environment
                    NODE_ENV=development

                    # Security Configuration
                    BCRYPT_SALT_ROUNDS=12

                    # Performance Monitoring Thresholds
                    MEMORY_WARNING_THRESHOLD=85
                    MEMORY_CRITICAL_THRESHOLD=95

                    # Rate Limiting Configuration
                    RATE_LIMIT_AUTH_MAX=1000
                    RATE_LIMIT_AUTH_WINDOW_MS=60000

                    # Global Rate Limiting Configuration
                    RATE_LIMIT_MAX_REQUESTS=10000
                    RATE_LIMIT_WINDOW_MS=60000
                    EOF'
                  fi
                - echo "Updating test environment files with database credentials..."
                - !Sub |
                  # Update .env.test.integration file
                  if [ -f "${VSCodeHomeFolder}/LGAM/backend/.env.test.integration" ]; then
                    sudo -u ${VSCodeUser} sed -i "s/^DB_USER=.*/DB_USER=\"${DbMasterUsername}\"/" ${VSCodeHomeFolder}/LGAM/backend/.env.test.integration
                    sudo -u ${VSCodeUser} sed -i "s/^DB_PASSWORD=.*/DB_PASSWORD=\"${DbPasswordPlaintext.password}\"/" ${VSCodeHomeFolder}/LGAM/backend/.env.test.integration
                    echo "Updated .env.test.integration file"
                  else
                    echo "Warning: .env.test.integration file not found"
                  fi
                - !Sub |
                  # Update .env.test.e2e file
                  if [ -f "${VSCodeHomeFolder}/LGAM/backend/.env.test.e2e" ]; then
                    sudo -u ${VSCodeUser} sed -i "s/^DB_USER=.*/DB_USER=\"${DbMasterUsername}\"/" ${VSCodeHomeFolder}/LGAM/backend/.env.test.e2e
                    sudo -u ${VSCodeUser} sed -i "s/^DB_PASSWORD=.*/DB_PASSWORD=\"${DbPasswordPlaintext.password}\"/" ${VSCodeHomeFolder}/LGAM/backend/.env.test.e2e
                    echo "Updated .env.test.e2e file"
                  else
                    echo "Warning: .env.test.e2e file not found"
                  fi
                - !Sub |
                  # Update .env.test.unit file
                  if [ -f "${VSCodeHomeFolder}/LGAM/backend/.env.test.unit" ]; then
                    sudo -u ${VSCodeUser} sed -i "s/^DB_USER=.*/DB_USER=\"${DbMasterUsername}\"/" ${VSCodeHomeFolder}/LGAM/backend/.env.test.unit
                    sudo -u ${VSCodeUser} sed -i "s/^DB_PASSWORD=.*/DB_PASSWORD=\"${DbPasswordPlaintext.password}\"/" ${VSCodeHomeFolder}/LGAM/backend/.env.test.unit
                    echo "Updated .env.test.unit file"
                  else
                    echo "Warning: .env.test.unit file not found"
                  fi
                - echo "Backend environment files configured successfully."
          - name: InstallBackendDependencies
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 600
              runCommand:
                - "#!/bin/bash"
                - "set -euo pipefail"
                - echo "Installing backend npm dependencies..."
                - !Sub |
                  # Install npm dependencies as participant user
                  sudo -u ${VSCodeUser} bash -c 'cd ${VSCodeHomeFolder}/LGAM/backend && source ~/.bashrc && export NVM_DIR="$HOME/.nvm" && [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh" && npm install'
                - echo "Backend npm dependencies installed successfully."
          - name: SetupDatabase
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 600
              runCommand:
                - "#!/bin/bash"
                - "set -euo pipefail"
                - echo "Setting up database for the backend application..."
                - !Sub |
                  # Change to backend directory and run database setup as participant user
                  sudo -u ${VSCodeUser} bash -c 'cd ${VSCodeHomeFolder}/LGAM/backend && source ~/.bashrc && export NVM_DIR="$HOME/.nvm" && [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh" && npm run db:test'
                - echo "Database connection test completed successfully."
                - !Sub |
                  # Initialize database schema
                  sudo -u ${VSCodeUser} bash -c 'cd ${VSCodeHomeFolder}/LGAM/backend && source ~/.bashrc && export NVM_DIR="$HOME/.nvm" && [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh" && npm run db:init'
                - echo "Database schema initialization completed successfully."
                - !Sub |
                  # Seed database with sample data
                  sudo -u ${VSCodeUser} bash -c 'cd ${VSCodeHomeFolder}/LGAM/backend && source ~/.bashrc && export NVM_DIR="$HOME/.nvm" && [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh" && npm run db:seed'
                - echo "Database seeding completed successfully."
                - echo "Database setup completed successfully."
          - name: SetupFrontEnd
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 600
              runCommand:
                - "#!/bin/bash"
                - "set -euo pipefail"
                - echo "Setting up frontend development environment..."
                - !Sub |
                  sudo -u ${VSCodeUser} bash -c 'cd ${VSCodeHomeFolder}/LGAM/frontend && source ~/.bashrc && export NVM_DIR="$HOME/.nvm" && [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh" && npm install'
                - echo "Frontend npm dependencies installed successfully."
                - echo "Frontend development environment setup completed successfully."
                - echo "Note - Frontend will be served from development server on port 3000 for live updates during workshop."
          - name: UpdateFrontEnd
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 600
              runCommand:
                - "#!/bin/bash"
                - "set -euo pipefail"
                - echo "Updating frontend CSP configuration..."
                - !Sub |
                  # Modify the build-csp.js file to comment out the production CSP and set it to empty string
                  if [ -f "${VSCodeHomeFolder}/LGAM/frontend/scripts/build-csp.js" ]; then
                    sudo -u ${VSCodeUser} bash -c 'cd ${VSCodeHomeFolder}/LGAM/frontend/scripts && cp build-csp.js build-csp.js.backup'
                    echo "Created backup of build-csp.js"
                    
                    # Comment out the existing productionCSP line and add the new empty one
                    sudo -u ${VSCodeUser} bash -c 'cd ${VSCodeHomeFolder}/LGAM/frontend/scripts && sed -i "s/^const productionCSP = \`.*\`;$/\/\/ &\nconst productionCSP = \`\`;/" build-csp.js'
                    echo "Updated build-csp.js - commented out original productionCSP and set to empty string"
                  else
                    echo "Warning: build-csp.js file not found"
                  fi
                - echo "Updating frontend index.html security headers..."
                - !Sub |
                  # Modify the index.html file to remove CSP and update security headers
                  if [ -f "${VSCodeHomeFolder}/LGAM/frontend/public/index.html" ]; then
                    sudo -u ${VSCodeUser} bash -c 'cd ${VSCodeHomeFolder}/LGAM/frontend/public && cp index.html index.html.backup'
                    echo "Created backup of index.html"
                    
                    # Update the security headers section
                    # First, change the comment
                    sudo -u ${VSCodeUser} bash -c 'cd ${VSCodeHomeFolder}/LGAM/frontend/public && sed -i "s/<!-- Security Headers - Environment-based CSP -->/<!-- Security Headers - Removed CSP for development -->/" index.html'
                    
                    # Remove the CSP meta tag (multi-line)
                    sudo -u ${VSCodeUser} bash -c 'cd ${VSCodeHomeFolder}/LGAM/frontend/public && sed -i "/meta http-equiv=\"Content-Security-Policy\"/,+1d" index.html'
                    
                    # Add the new comment after the first comment
                    sudo -u ${VSCodeUser} bash -c 'cd ${VSCodeHomeFolder}/LGAM/frontend/public && sed -i "/<!-- Security Headers - Removed CSP for development -->/a\    <!-- CSP removed to eliminate development issues -->" index.html'
                    
                    # Update X-Frame-Options content from DENY to empty
                    sudo -u ${VSCodeUser} bash -c 'cd ${VSCodeHomeFolder}/LGAM/frontend/public && sed -i "s/content=\"DENY\"/content=\"\"/" index.html'
                    
                    echo "Updated index.html - removed CSP and updated X-Frame-Options"
                  else
                    echo "Warning: index.html file not found"
                  fi
                - echo "Frontend CSP configuration updated successfully."
          - name: SetupGit
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 600
              runCommand:
                - "#!/bin/bash"
                - "set -euo pipefail"
                - echo "Setting up Git repository for modernizer project..."
                - !Sub |
                  # Initialize git repository in modernizer directory as participant user
                  sudo -u ${VSCodeUser} bash -c 'cd ${VSCodeHomeFolder}/LGAM && git init'
                - !Sub |
                  # Create .gitignore file with comprehensive content
                  sudo -u ${VSCodeUser} bash -c 'cat > ${VSCodeHomeFolder}/LGAM/.gitignore <<EOF
                  # Dependencies
                  node_modules/
                  npm-debug.log*
                  yarn-debug.log*
                  yarn-error.log*
                  
                  # Build outputs
                  dist/
                  build/
                  coverage/
                  *.tsbuildinfo
                  
                  # Environment files
                  .env
                  .env.local
                  .env.development.local
                  .env.test.local
                  .env.production.local
                  
                  # IDE files
                  .vscode/
                  .idea/
                  *.swp
                  *.swo
                  
                  # OS files
                  .DS_Store
                  Thumbs.db
                  
                  # Logs
                  logs/
                  *.log
                  
                  # Runtime data
                  pids/
                  *.pid
                  *.seed
                  *.pid.lock
                  
                  # Test results
                  test-results/
                  cypress/videos/
                  cypress/screenshots/
                  
                  # Temporary files
                  tmp/
                  temp/
                  .amazonq
                  .venv
                  EOF'
                - !Sub |
                  # Add all files to staging area
                  sudo -u ${VSCodeUser} bash -c 'cd ${VSCodeHomeFolder}/LGAM && git add .'
                - !Sub |
                  # Create initial commit
                  sudo -u ${VSCodeUser} bash -c 'cd ${VSCodeHomeFolder}/LGAM && git commit -m "Initial commit - modernizer e-commerce application setup"'
                - echo "Git repository initialized successfully with .gitignore and initial commit."
          - name: SetupToolsConfigurationFile
            action: aws:runShellScript
            inputs:
              timeoutSeconds: 600
              runCommand:
                - "#!/bin/bash"
                - "set -euo pipefail"
                - echo "Setting up tools configuration file with CloudFormation values"
                - !Sub |
                  # Update all CloudFormation placeholder values in config.json
                  sudo -u ${VSCodeUser} sed -i 's/111122223333/${AWS::AccountId}/g' ${VSCodeHomeFolder}/LGAM/tools/config.json
                  sudo -u ${VSCodeUser} sed -i 's/<CF S3 BUCKET>/${MigrationS3Bucket}/g' ${VSCodeHomeFolder}/LGAM/tools/config.json
                  sudo -u ${VSCodeUser} sed -i 's|<CF GLUE ROLE>|${GlueServiceRole.Arn}|g' ${VSCodeHomeFolder}/LGAM/tools/config.json
                  sudo -u ${VSCodeUser} sed -i 's/<CF VPC ID>/${VSCodeInstance.VpcId}/g' ${VSCodeHomeFolder}/LGAM/tools/config.json
                  sudo -u ${VSCodeUser} sed -i 's/<CF SUBNET IDS>/${VSCodeInstance.SubnetId}/g' ${VSCodeHomeFolder}/LGAM/tools/config.json
                  sudo -u ${VSCodeUser} sed -i 's/<CF SECURITY GROUP ID>/${SecurityGroup.GroupId}/g' ${VSCodeHomeFolder}/LGAM/tools/config.json
                  sudo -u ${VSCodeUser} sed -i 's/<CF PUBLIC IP>/${VSCodeInstance.PublicIp}/g' ${VSCodeHomeFolder}/LGAM/tools/config.json
                  sudo -u ${VSCodeUser} sed -i 's/<CF PRIVATE IP>/${VSCodeInstance.PrivateIp}/g' ${VSCodeHomeFolder}/LGAM/tools/config.json
                  sudo -u ${VSCodeUser} sed -i 's/<CF DB USERNAME>/${DbMasterUsername}/g' ${VSCodeHomeFolder}/LGAM/tools/config.json
                  sudo -u ${VSCodeUser} sed -i 's/<CF DB PASSWORD>/${DbPasswordPlaintext.password}/g' ${VSCodeHomeFolder}/LGAM/tools/config.json
                - echo "Configuration file updated with CloudFormation values successfully."

  SSMDocLambdaRole:
    Type: AWS::IAM::Role
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W11
            reason: The Amazon EC2 ssm:*CommandInvocation API actions do not support resource-level permissions, so you cannot control which individual resources users can view in the console. Therefore, the * wildcard is necessary in the Resource element. See https://docs.aws.amazon.com/service-authorization/latest/reference/list_awssystemsmanager.html
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: !Sub lambda.${AWS::URLSuffix}
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - !Sub arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: SSMDocOnEC2
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - ssm:SendCommand
                Resource:
                  - !Sub arn:${AWS::Partition}:ssm:${AWS::Region}:${AWS::AccountId}:document/${VSCodeSSMDoc}
                  - !Sub arn:${AWS::Partition}:ssm:${AWS::Region}:${AWS::AccountId}:document/AmazonCloudWatch-ManageAgent
                  - !Sub arn:${AWS::Partition}:ec2:${AWS::Region}:${AWS::AccountId}:instance/${VSCodeInstance}
              - Effect: Allow
                Action:
                  - ssm:ListCommandInvocations
                  - ssm:GetCommandInvocation
                Resource: "*"

  RunSSMDocLambda:
    Type: AWS::Lambda::Function
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W58
            reason: Warning incorrectly reported. The role associated with the Lambda function has the AWSLambdaBasicExecutionRole managed policy attached, which includes permission to write CloudWatch Logs. See https://docs.aws.amazon.com/aws-managed-policy/latest/reference/AWSLambdaBasicExecutionRole.html
          - id: W89
            reason: CloudFormation custom function does not need the scaffolding of a VPC, to do so would add unnecessary complexity
          - id: W92
            reason: CloudFormation custom function does not need reserved concurrent executions, to do so would add unnecessary complexity
    Properties:
      Description: Run SSM document on EC2 instance
      Handler: index.lambda_handler
      Runtime: python3.13
      MemorySize: 128
      Timeout: 600
      Environment:
        Variables:
          RetrySleep: 2900
          AbortTimeRemaining: 3200
      Architectures:
        - arm64
      Role: !GetAtt SSMDocLambdaRole.Arn
      Code:
        ZipFile: |
          import boto3
          import cfnresponse
          import logging
          import time
          import os

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def lambda_handler(event, context):
              logger.debug(f'event: {event}')
              logger.debug(f'context: {context}')

              if event['RequestType'] != 'Create':
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData={}, reason='No action to take')
              else:
                  sleep_ms = int(os.environ.get('RetrySleep'))
                  abort_time_remaining_ms = int(os.environ.get('AbortTimeRemaining'))
                  resource_properties = event['ResourceProperties']
                  instance_id = resource_properties['InstanceId']
                  document_name = resource_properties['DocumentName']
                  cloudwatch_log_group_name = resource_properties['CloudWatchLogGroupName']

                  logger.info(f'Running SSM Document {document_name} on EC2 instance {instance_id}. Logging to {cloudwatch_log_group_name}')

                  del resource_properties['ServiceToken']
                  if 'ServiceTimeout' in resource_properties:
                      del resource_properties['ServiceTimeout']
                  del resource_properties['InstanceId']
                  del resource_properties['DocumentName']
                  del resource_properties['CloudWatchLogGroupName']
                  if 'PhysicalResourceId' in resource_properties:
                      del resource_properties['PhysicalResourceId']

                  logger.debug(f'resource_properties filtered: {resource_properties}')

                  parameters = {}
                  for key, value in resource_properties.items():
                      parameters[key] = [value]

                  logger.debug(f'parameters: {parameters}')

                  retry = True
                  attempt_no = 0
                  time_remaining_ms = context.get_remaining_time_in_millis()

                  ssm = boto3.client('ssm')

                  while (retry == True):
                      attempt_no += 1
                      logger.info(f'Attempt: {attempt_no}. Time Remaining: {time_remaining_ms/1000}s')
                      try:
                          response = ssm.send_command(
                              InstanceIds = [instance_id],
                              DocumentName = document_name,
                              CloudWatchOutputConfig = {'CloudWatchLogGroupName': cloudwatch_log_group_name, 'CloudWatchOutputEnabled': True},
                              Parameters = parameters
                          )
                          logger.debug(f'response: {response}')
                          command_id = response['Command']['CommandId']
                          responseData = {'CommandId': command_id}
                          cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData, reason='OK')
                          retry = False

                      except ssm.exceptions.InvalidInstanceId as e:
                          time_remaining_ms = context.get_remaining_time_in_millis()
                          if (time_remaining_ms > abort_time_remaining_ms):
                              logger.info(f'Instance {instance_id} not ready. Sleeping: {sleep_ms/1000}s')
                              time.sleep(sleep_ms/1000)
                              retry = True
                          else:
                              logger.info(f'Instance {instance_id} not ready, timed out. Time remaining {time_remaining_ms/1000}s < Abort time remaining {abort_time_remaining_ms/1000}s')
                              logger.error(e, exc_info=True)
                              cfnresponse.send(event, context, cfnresponse.FAILED, responseData={}, reason='Timed out. Time remaining: ' + str(time_remaining_ms/1000) + 's < Abort time remaining: ' + str(abort_time_remaining_ms/1000) + 's')
                              retry = False

                      except Exception as e:
                          logger.error(e, exc_info=True)
                          cfnresponse.send(event, context, cfnresponse.FAILED, responseData={}, reason=str(e))
                          retry = False

  RunVSCodeSSMDoc:
    Type: Custom::RunSSMDocLambda
    DependsOn: VSCodeInstance
    Properties:
      ServiceToken: !GetAtt RunSSMDocLambda.Arn
      ServiceTimeout: 600
      InstanceId: !Ref VSCodeInstance
      DocumentName: !Ref VSCodeSSMDoc
      CloudWatchLogGroupName: !Sub /aws/ssm/${VSCodeSSMDoc}
      VSCodePassword: !GetAtt SecretPlaintext.password
      LinuxFlavor: al2023
      PythonMajorMinor: !Ref PythonMajorMinor
      
  VSCodeHealthCheckLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: !Sub lambda.${AWS::URLSuffix}
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - !Sub arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole

  VSCodeHealthCheckLambda:
    Type: AWS::Lambda::Function
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W58
            reason: Warning incorrectly reported. The role associated with the Lambda function has the AWSLambdaBasicExecutionRole managed policy attached, which includes permission to write CloudWatch Logs. See https://docs.aws.amazon.com/aws-managed-policy/latest/reference/AWSLambdaBasicExecutionRole.html
          - id: W89
            reason: CloudFormation custom function does not need the scaffolding of a VPC, to do so would add unnecessary complexity
          - id: W92
            reason: CloudFormation custom function does not need reserved concurrent executions, to do so would add unnecessary complexity
    Properties:
      Description: Run health check on VS code-server instance
      Handler: index.lambda_handler
      Runtime: python3.13
      MemorySize: 128
      Timeout: 600
      Environment:
        Variables:
          RetrySleep: 2900
          AbortTimeRemaining: 5000
      Architectures:
        - arm64
      Role: !GetAtt VSCodeHealthCheckLambdaRole.Arn
      Code:
        ZipFile: |
          import json
          import cfnresponse
          import logging
          import time
          import os
          import http.client
          from urllib.parse import urlparse

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def healthURLOk(url):
              # Using try block to catch connection errors and JSON conversion errors
              try:
                  logger.debug(f'url: {url}')
                  parsed_url = urlparse(url)
                  if parsed_url.scheme == 'https':
                      logger.debug(f'Trying https: {parsed_url.netloc}. Parsed_url: {parsed_url}')
                      conn = http.client.HTTPSConnection(parsed_url.netloc)
                  else:
                      logger.debug(f'Trying http: {parsed_url.netloc}. Parsed_url: {parsed_url}')
                      conn = http.client.HTTPConnection(parsed_url.netloc)
                  conn.request("GET", parsed_url.path or "/")
                  response = conn.getresponse()
                  logger.debug(f'response: {response}')
                  logger.debug(f'response.status: {response.status}')
                  content = response.read()
                  logger.debug(f'content: {content}')
                  # This will be true for any return code below 4xx (so 3xx and 2xx)
                  if 200 <= response.status < 400:
                      response_dict = json.loads(content.decode('utf-8'))
                      logger.debug(f'response_dict: {response_dict}')
                      # Checking for expected keys and if the key has the expected value
                      if 'status' in response_dict and (response_dict['status'].lower() == 'alive' or response_dict['status'].lower() == 'expired'):
                          # Response code 200 and correct JSON returned
                          logger.info(f'Health check OK. Status: {response_dict["status"].lower()}')
                          return True
                      else:
                          # Response code 200 but the 'status' key is either not present or does not have the value 'alive' or 'expired'
                          logger.info(f'Health check failed. Status: {response_dict["status"].lower()}')
                          return False
                  else:
                      # Response was not ok (error 4xx or 5xx)
                      logger.info(f'Healthcheck failed. Return code: {response.status}')
                      return False

              except http.client.HTTPException as e:
                  # URL malformed or endpoint not ready yet, this should only happen if we can not DNS resolve the URL
                  logger.error(e, exc_info=True)
                  logger.error(f'Healthcheck failed: HTTP Exception. URL invalid and/or endpoint not ready yet')
                  return False

              except json.decoder.JSONDecodeError as e:
                  # The response we got was not a properly formatted JSON
                  logger.error(e, exc_info=True)
                  logger.info(f'Healthcheck failed: Did not get JSON object from URL as expected')
                  return False

              except Exception as e:
                  logger.error(e, exc_info=True)
                  logger.info(f'Healthcheck failed: General error')
                  return False

              finally:
                  if 'conn' in locals():
                      conn.close()

          def is_valid_json(json_string):
              try:
                  json.loads(json_string)
                  return True
              except ValueError:
                  return False

          def lambda_handler(event, context):
              logger.debug(f'event: {event}')
              logger.debug(f'context: {context}')
              try:
                  if event['RequestType'] != 'Create':
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData={}, reason='No action to take')
                  else:
                      sleep_ms = int(os.environ.get('RetrySleep'))
                      abort_time_remaining_ms = int(os.environ.get('AbortTimeRemaining'))
                      resource_properties = event['ResourceProperties']
                      url = resource_properties['Url']

                      logger.info(f'Testing url: {url}')

                      time_remaining_ms = context.get_remaining_time_in_millis()
                      attempt_no = 0
                      health_check = False
                      while (attempt_no == 0 or (time_remaining_ms > abort_time_remaining_ms and not health_check)):
                          attempt_no += 1
                          logger.info(f'Attempt: {attempt_no}. Time Remaining: {time_remaining_ms/1000}s')
                          health_check = healthURLOk(url)
                          if not health_check:
                              logger.debug(f'Healthcheck failed. Sleeping: {sleep_ms/1000}s')
                              time.sleep(sleep_ms/1000)
                          time_remaining_ms = context.get_remaining_time_in_millis()
                      if health_check:
                          logger.info(f'Health check successful. Attempts: {attempt_no}. Time Remaining: {time_remaining_ms/1000}s')
                          cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData={}, reason='VS code-server healthcheck successful')
                      else:
                          logger.info(f'Health check failed. Timed out. Attempts: {attempt_no}. Time remaining {time_remaining_ms/1000}s < Abort time remaining {abort_time_remaining_ms/1000}s')
                          cfnresponse.send(event, context, cfnresponse.FAILED, responseData={}, reason='VS code-server healthcheck failed. Timed out after ' + str(attempt_no) + ' attempts')
                          logger.info(f'Response sent')

              except Exception as e:
                  logger.error(e, exc_info=True)
                  logger.info(f'Health check failed. General exception')
                  cfnresponse.send(event, context, cfnresponse.FAILED, responseData={}, reason=str(e))

  Healthcheck:
    Type: Custom::VSCodeHealthCheckLambda
    Properties:
      ServiceToken: !GetAtt VSCodeHealthCheckLambda.Arn
      ServiceTimeout: 610
      Url: !Sub https://${CloudFrontDistribution.DomainName}/healthz

  CheckSSMDocLambda:
    Type: AWS::Lambda::Function
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W58
            reason: Warning incorrectly reported. The role associated with the Lambda function has the AWSLambdaBasicExecutionRole managed policy attached, which includes permission to write CloudWatch Logs. See https://docs.aws.amazon.com/aws-managed-policy/latest/reference/AWSLambdaBasicExecutionRole.html
          - id: W89
            reason: CloudFormation custom function does not need the scaffolding of a VPC, to do so would add unnecessary complexity
          - id: W92
            reason: CloudFormation custom function does not need reserved concurrent executions, to do so would add unnecessary complexity
    Properties:
      Description: Check SSM document on EC2 instance
      Handler: index.lambda_handler
      Runtime: python3.13
      MemorySize: 128
      Timeout: 600
      Environment:
        Variables:
          RetrySleep: 2900
          AbortTimeRemaining: 5000
      Architectures:
        - arm64
      Role: !GetAtt SSMDocLambdaRole.Arn
      Code:
        ZipFile: |
          import boto3
          import cfnresponse
          import logging
          import time
          import os

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def lambda_handler(event, context):
              logger.debug(f'event: {event}')
              logger.debug(f'context: {context}')

              if event['RequestType'] != 'Create':
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData={}, reason='No action to take')
              else:
                  sleep_ms = int(os.environ.get('RetrySleep'))
                  abort_time_remaining_ms = int(os.environ.get('AbortTimeRemaining'))
                  resource_properties = event['ResourceProperties']
                  instance_id = resource_properties['InstanceId']
                  document_name = resource_properties['DocumentName']

                  logger.info(f'Checking SSM Document {document_name} on EC2 instance {instance_id}')

                  retry = True
                  attempt_no = 0
                  time_remaining_ms = context.get_remaining_time_in_millis()

                  ssm = boto3.client('ssm')

                  while (retry == True):
                      attempt_no += 1
                      logger.info(f'Attempt: {attempt_no}. Time Remaining: {time_remaining_ms/1000}s')
                      try:
                          # check to see if document has completed running on instance
                          response = ssm.list_command_invocations(
                              InstanceId=instance_id,
                              Details=True
                          )
                          logger.debug(f'Response: {response}')
                          for invocation in response['CommandInvocations']:
                              if invocation['DocumentName'] == document_name:
                                  invocation_status = invocation['Status']
                                  if invocation_status == 'Success':
                                      logger.info(f'SSM Document {document_name} on EC2 instance {instance_id} complete. Status: {invocation_status}')                                  
                                      cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData={}, reason='OK')
                                      retry = False
                                  elif invocation_status == 'Failed' or invocation_status == 'Cancelled' or invocation_status == 'TimedOut':
                                      logger.info(f'SSM Document {document_name} on EC2 instance {instance_id} failed. Status: {invocation_status}')
                                      reason = ''
                                      # Get information on step that failed, otherwise it's cancelled or timeout
                                      for step in invocation['CommandPlugins']:
                                          step_name = step['Name']
                                          step_status = step['Status']
                                          step_output = step['Output']
                                          logger.debug(f'Step {step_name} {step_status}: {step_output}')
                                          if step_status != 'Success':
                                              try:
                                                  response_step = ssm.get_command_invocation(
                                                      CommandId=invocation['CommandId'],
                                                      InstanceId=instance_id,
                                                      PluginName=step_name
                                                  )
                                                  logger.debug(f'Step details: {response_step}')
                                                  step_output = response_step['StandardErrorContent']
                                              except Exception as e:
                                                  logger.error(e, exc_info=True)
                                              logger.info(f'Step {step_name} {step_status}: {step_output}')
                                              if reason == '':
                                                  reason = f'Step {step_name} {step_status}: {step_output}'
                                              else:
                                                  reason += f'\nStep {step_name} {step_status}: {step_output}'
                                      if reason == '':
                                          reason = f'SSM Document {document_name} on EC2 instance {instance_id} failed. Status: {invocation_status}'
                                      logger.info(f'{reason}')
                                      cfnresponse.send(event, context, cfnresponse.FAILED, responseData={}, reason=reason)
                                      retry = False
                                  else:
                                      logger.info(f'SSM Document {document_name} on EC2 instance {instance_id} not yet complete. Status: {invocation_status}')
                                      retry = True
                          if retry == True:
                              if (time_remaining_ms > abort_time_remaining_ms):
                                  logger.info(f'Sleeping: {sleep_ms/1000}s')
                                  time.sleep(sleep_ms/1000)
                                  time_remaining_ms = context.get_remaining_time_in_millis()
                              else:
                                  logger.info(f'Time remaining {time_remaining_ms/1000}s < Abort time remaining {abort_time_remaining_ms/1000}s')
                                  logger.info(f'Aborting check as time remaining {time_remaining_ms/1000}s < Abort time remaining {abort_time_remaining_ms/1000}s')
                                  cfnresponse.send(event, context, cfnresponse.FAILED, responseData={}, reason='Timed out. Time remaining: ' + str(time_remaining_ms/1000) + 's < Abort time remaining: ' + str(abort_time_remaining_ms/1000) + 's')
                                  retry = False
                      except Exception as e:
                          logger.error(e, exc_info=True)
                          cfnresponse.send(event, context, cfnresponse.FAILED, responseData={}, reason=str(e))
                          retry = False

  CheckVSCodeSSMDoc:
    Type: Custom::CheckSSMDocLambda
    DependsOn: Healthcheck
    Properties:
      ServiceToken: !GetAtt CheckSSMDocLambda.Arn
      ServiceTimeout: 610
      InstanceId: !Ref VSCodeInstance
      DocumentName: !Ref VSCodeSSMDoc

  CodeInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Roles:
        - !Ref CodeInstanceRole

  VSCodeInstance:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: !Ref DBLatestAmiId
      InstanceType: !GetAtt VSCodeFindTheInstanceTypeLambda.InstanceType
      BlockDeviceMappings:
        - DeviceName: /dev/xvda
          Ebs:
            VolumeSize: !Ref VSCodeInstanceVolumeSize
            VolumeType: gp3
            DeleteOnTermination: true
            Encrypted: true
      Monitoring: true
      SecurityGroupIds:
        - !GetAtt SecurityGroup.GroupId
      IamInstanceProfile: !Ref CodeInstanceProfile
      SubnetId: !GetAtt VSCodeFindTheInstanceTypeLambda.SubnetId
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash -ex
          exec > >(tee /var/log/user-data.log|logger -t user-data -s 2>/dev/console) 2>&1
          echo "Starting minimal VSCode Server setup at $(date)"
          
          # Update system and install base packages
          yum update -y
          yum install -y curl wget unzip

          # Create minimal directories for the SSM Document to use later
          mkdir -p ${VSCodeHomeFolder}
          
          echo "Minimal setup completed. The VSCodeSSMDoc will handle the rest of the configuration."
      Tags:
        - Key: Name
          Value: !Ref VSCodeInstanceName


  SecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: F1000
            reason: All outbound traffic should be allowed from this instance. The EC2 instance is provisioned in the default VPC, which already has this egress rule, and it is not possible to duplicate this egress rule in the default VPC
    Properties:
      GroupDescription: SG for VSCodeServer - allow HTTP access from specified IP
      SecurityGroupIngress:
        - Description: Allow MySQL from specified IP address
          IpProtocol: tcp
          FromPort: 3306
          ToPort: 3306
          CidrIp: !Ref AllowedIP
        - Description: Allow MySQL from VPC CIDR (for Glue connectivity)
          IpProtocol: tcp
          FromPort: 3306
          ToPort: 3306
          CidrIp: 172.31.0.0/16
        - Description: Allow HTTP from com.amazonaws.global.cloudfront.origin-facing
          IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          SourcePrefixListId:
            !FindInMap [AWSRegionsPrefixListID, !Ref "AWS::Region", PrefixList]

  VSCodeInstanceCachePolicy:
    Type: AWS::CloudFront::CachePolicy
    Properties:
      CachePolicyConfig:
        DefaultTTL: 86400
        MaxTTL: 31536000
        MinTTL: 1
        Name: !Sub
          - ${VSCodeInstanceName}-${RandomGUID}
          - RandomGUID:
              !Select [
                0,
                !Split ["-", !Select [2, !Split ["/", !Ref AWS::StackId]]],
              ]
        ParametersInCacheKeyAndForwardedToOrigin:
          CookiesConfig:
            CookieBehavior: all
          EnableAcceptEncodingGzip: False
          HeadersConfig:
            HeaderBehavior: whitelist
            Headers:
              - Accept-Charset
              - Authorization
              - Origin
              - Accept
              - Referer
              - Host
              - Accept-Language
              - Accept-Encoding
              - Accept-Datetime
          QueryStringsConfig:
            QueryStringBehavior: all

  CloudFrontDistribution:
    Type: AWS::CloudFront::Distribution
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W10
            reason: CloudFront Distribution access logging would require setup of an S3 bucket and changes in IAM, which add unnecessary complexity to the template
          - id: W70
            reason: Workshop Studio does not include a domain that can be used to provision a certificate, so it is not possible to setup TLS. See PFR EE-6016
    Properties:
      DistributionConfig:
        Enabled: True
        HttpVersion: http2and3
        CacheBehaviors:
          - AllowedMethods:
              - GET
              - HEAD
              - OPTIONS
              - PUT
              - PATCH
              - POST
              - DELETE
            CachePolicyId: 4135ea2d-6df8-44a3-9df3-4b5a84be39ad # see https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-managed-cache-policies.html#managed-cache-policy-caching-disabled
            Compress: False
            OriginRequestPolicyId: 216adef6-5c7f-47e4-b989-5492eafa07d3 # Managed-AllViewer - see https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-managed-origin-request-policies.html#:~:text=When%20using%20AWS,47e4%2Db989%2D5492eafa07d3
            TargetOriginId: !Sub CloudFront-${AWS::StackName}
            ViewerProtocolPolicy: allow-all
            PathPattern: "/proxy/*"
        DefaultCacheBehavior:
          AllowedMethods:
            - GET
            - HEAD
            - OPTIONS
            - PUT
            - PATCH
            - POST
            - DELETE
          CachePolicyId: !Ref VSCodeInstanceCachePolicy
          OriginRequestPolicyId: 216adef6-5c7f-47e4-b989-5492eafa07d3 # Managed-AllViewer - see https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-managed-origin-request-policies.html#:~:text=When%20using%20AWS,47e4%2Db989%2D5492eafa07d3
          TargetOriginId: !Sub CloudFront-${AWS::StackName}
          ViewerProtocolPolicy: allow-all
        Origins:
          - DomainName: !GetAtt VSCodeInstance.PublicDnsName
            Id: !Sub CloudFront-${AWS::StackName}
            CustomOriginConfig:
              OriginProtocolPolicy: http-only

  # Self-referencing security group rule for Glue job communication
  SecurityGroupSelfIngress:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      Description: Allow all traffic from same security group (required for AWS Glue)
      GroupId: !GetAtt SecurityGroup.GroupId
      IpProtocol: -1
      SourceSecurityGroupId: !GetAtt SecurityGroup.GroupId

  # VPC Endpoints for Glue to access AWS services
  # AWS Glue requires Gateway endpoints for S3 and DynamoDB
  RouteTableLookupRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - !Sub arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: EC2RouteTableAccess
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - ec2:DescribeRouteTables
                  - ec2:DescribeSubnets
                Resource: '*'

  RouteTableLookupFunction:
    Type: AWS::Lambda::Function
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W58
            reason: Lambda execution role has basic execution permissions
          - id: W89
            reason: Lambda function does not need VPC configuration
          - id: W92
            reason: Lambda function does not need provisioned concurrency
    Properties:
      Handler: index.handler
      Role: !GetAtt RouteTableLookupRole.Arn
      Runtime: python3.13
      MemorySize: 128
      Timeout: 60
      Code:
        ZipFile: |
          import boto3
          import cfnresponse
          import logging

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def handler(event, context):
              try:
                  if event['RequestType'] == 'Delete':
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, {})
                      return

                  subnet_id = event['ResourceProperties']['SubnetId']
                  vpc_id = event['ResourceProperties']['VpcId']
                  
                  ec2 = boto3.client('ec2')
                  
                  # First check if subnet has explicit route table association
                  response = ec2.describe_route_tables(
                      Filters=[
                          {'Name': 'association.subnet-id', 'Values': [subnet_id]}
                      ]
                  )
                  
                  if response['RouteTables']:
                      route_table_id = response['RouteTables'][0]['RouteTableId']
                      logger.info(f'Found explicit route table: {route_table_id}')
                  else:
                      # If no explicit association, find main route table for VPC
                      response = ec2.describe_route_tables(
                          Filters=[
                              {'Name': 'vpc-id', 'Values': [vpc_id]},
                              {'Name': 'association.main', 'Values': ['true']}
                          ]
                      )
                      if response['RouteTables']:
                          route_table_id = response['RouteTables'][0]['RouteTableId']
                          logger.info(f'Using main route table: {route_table_id}')
                      else:
                          raise Exception(f'No route table found for VPC {vpc_id}')
                  
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, {'RouteTableId': route_table_id})
                  
              except Exception as e:
                  logger.error(f'Error: {str(e)}')
                  cfnresponse.send(event, context, cfnresponse.FAILED, {}, str(e))

  RouteTableLookup:
    Type: Custom::RouteTableLookup
    Properties:
      ServiceToken: !GetAtt RouteTableLookupFunction.Arn
      SubnetId: !GetAtt VSCodeInstance.SubnetId
      VpcId: !GetAtt VSCodeInstance.VpcId

  S3VPCEndpoint:
    Type: AWS::EC2::VPCEndpoint
    Properties:
      VpcId: !GetAtt VSCodeInstance.VpcId
      ServiceName: !Sub com.amazonaws.${AWS::Region}.s3
      VpcEndpointType: Gateway
      RouteTableIds:
        - !GetAtt RouteTableLookup.RouteTableId

  DynamoDBVPCEndpoint:
    Type: AWS::EC2::VPCEndpoint
    Properties:
      VpcId: !GetAtt VSCodeInstance.VpcId
      ServiceName: !Sub com.amazonaws.${AWS::Region}.dynamodb
      VpcEndpointType: Gateway
      RouteTableIds:
        - !GetAtt RouteTableLookup.RouteTableId

  # Security group for VPC endpoints
  VpcEndpointSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for VPC endpoints
      VpcId: !GetAtt VSCodeInstance.VpcId
      SecurityGroupIngress:
        - Description: Allow HTTPS inbound from the instance security group
          IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          SourceSecurityGroupId: !GetAtt SecurityGroup.GroupId

  # VPC Endpoint for AWS Secrets Manager (required for Glue connections with stored credentials)
  SecretsManagerVPCEndpoint:
    Type: AWS::EC2::VPCEndpoint
    Properties:
      VpcId: !GetAtt VSCodeInstance.VpcId
      ServiceName: !Sub com.amazonaws.${AWS::Region}.secretsmanager
      VpcEndpointType: Interface
      SubnetIds:
        - !GetAtt VSCodeInstance.SubnetId
      SecurityGroupIds:
        - !GetAtt VpcEndpointSecurityGroup.GroupId
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal: '*'
            Action:
              - secretsmanager:GetSecretValue
              - secretsmanager:DescribeSecret
            Resource: '*'

  # Security group for Glue connections
  GlueConnectionSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for Glue connections to MySQL
      VpcId: !GetAtt VSCodeInstance.VpcId
      SecurityGroupIngress:
        - Description: Allow MySQL from Glue jobs
          IpProtocol: tcp
          FromPort: 3306
          ToPort: 3306
          CidrIp: 172.31.0.0/16

  # Allow incoming connections from Glue security group to MySQL on VSCode instance
  MySQLSecurityGroupIngress:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      Description: Allow MySQL from Glue security group
      GroupId: !GetAtt SecurityGroup.GroupId
      IpProtocol: tcp
      FromPort: 3306
      ToPort: 3306
      SourceSecurityGroupId: !GetAtt GlueConnectionSecurityGroup.GroupId

  # AWS Glue Connection for MySQL Database
  MySQLGlueConnection:
    Type: AWS::Glue::Connection
    DependsOn:
      - VSCodeInstance
      - GlueConnectionSecurityGroup
    Properties:
      CatalogId: !Ref AWS::AccountId
      ConnectionInput:
        Name: mysql-modernizer-connection-test
        Description: MySQL connection for DynamoDB modernization workshop
        ConnectionType: JDBC
        ConnectionProperties:
          JDBC_CONNECTION_URL: !Sub "jdbc:mysql://${VSCodeInstance.PrivateIp}:3306/online_shopping_store"
          USERNAME: !Ref DbMasterUsername
          PASSWORD: !GetAtt DbPasswordPlaintext.password
        PhysicalConnectionRequirements:
          AvailabilityZone: !GetAtt VSCodeInstance.AvailabilityZone
          SecurityGroupIdList:
            - !GetAtt GlueConnectionSecurityGroup.GroupId
          SubnetId: !GetAtt VSCodeInstance.SubnetId


Outputs:
  VSCodePassword:
    Description: VSCode Server Password (stored in AWS Secrets Manager)
    Value: !GetAtt SecretPlaintext.password
  VSCodePublicIP:
    Description: VSCode Server Public IP Address
    Value: !GetAtt VSCodeInstance.PublicIp
  MigrationS3Bucket:
    Description: S3 Bucket for Migration
    Value: !Ref MigrationS3Bucket
  MySQLCredentials:
    Description: MySQL Database Credentials
    Value: !Sub "Username: ${DbMasterUsername}, Password: ${DbPasswordPlaintext.password}"
  DatabasePasswordSecret:
    Description: AWS Secrets Manager Secret Name for Database Password
    Value: !Ref DbPasswordSecret
  VSCodeServerURL:
    Description: VSCode-Server URL
    Value: !Sub https://${CloudFrontDistribution.DomainName}/?folder=${VSCodeHomeFolder}&tkn=${SecretPlaintext.password}

